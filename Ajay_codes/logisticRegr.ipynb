{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd04b4c8b610809c3f9bc9ea525554bf1b883bc2ecb7a4909389cc326e334cde335",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "4b4c8b610809c3f9bc9ea525554bf1b883bc2ecb7a4909389cc326e334cde335"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "import sklearn \n",
    "import string\n",
    "import re # helps you filter urls\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import datetime\n",
    "from datetime import datetime, time, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from calendar import monthrange\n",
    "import time\n",
    "import timeit\n",
    "import sklearn\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from pandas import read_csv\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.svm import SVC \n",
    "import sklearn.metrics as metrics\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(test, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    clean = re.compile('<.*?>')\n",
    "    test=re.sub(clean, '', test)\n",
    "    posMapping = {# \"First_Letter by nltk.pos_tag\":\"POS_for_lemmatizer\"\n",
    "            \"N\":'n',\n",
    "            \"V\":'v',\n",
    "            \"J\":'a',\n",
    "            \"R\":'r'}\n",
    "    url_reg='http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    words=re.sub(url_reg, '', test)\n",
    "    words=words.replace('\\'s', '')\n",
    "    words=words.replace('\\'', '')\n",
    "    words = [word.lower() for word in words]  \n",
    "    listnew=[]\n",
    "    for i in words:\n",
    "          if i in string.punctuation:\n",
    "              listnew.append(\" \")\n",
    "          else:\n",
    "              listnew.append(i)        \n",
    "    words=\"\".join(listnew)\n",
    "    words=nltk.word_tokenize(words)\n",
    "    def lemmatizerfunction(word,pos):\n",
    "          if pos==None:\n",
    "              return(None)\n",
    "          else:\n",
    "              result=lemmatizer.lemmatize(word,pos)\n",
    "              return(result)  \n",
    "    \n",
    "    list1=nltk.pos_tag(words)\n",
    "    \n",
    "    list1=[ele[1] for ele in list1]   \n",
    "    list1=[ele[0] for ele in list1]     \n",
    "    def converter(x):\n",
    "        if x in posMapping:\n",
    "            return(posMapping[x])\n",
    "        else:     \n",
    "            return('n')      \n",
    "    list1=[converter(i) for i in list1]  \n",
    "    listfinal=list(zip(words,list1))\n",
    "    listfinal=[lemmatizerfunction(i[0],i[1]) for i in listfinal]\n",
    "    return(listfinal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all(df, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    df['text']=df.apply(lambda row : process(row['text'],lemmatizer), axis = 1) \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(processed_tweets, stopwords):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords,min_df=2,ngram_range=(1,2))\n",
    "    corpus=[\" \".join(review) for review in processed_tweets['text'].values]\n",
    "    sm=vectorizer.fit_transform(corpus)\n",
    "    return(vectorizer,sm)\n",
    "\n",
    "def create_labels(processed_tweets):\n",
    "    df=processed_tweets\n",
    "    Y=df['sentiment']\n",
    "    return(Y)\n",
    "\n",
    "\n",
    "def learn_classifier(X_train, y_train, kernel,C,gamma):\n",
    "    clf = SVC(kernel=kernel, C=C,gamma=gamma)\n",
    "    #print(kernel)\n",
    "    y_train=y_train.astype('int')\n",
    "    clf.fit(X_train,y_train)\n",
    "    return(clf)\n",
    "\n",
    "# execute code\n",
    "def evaluate_classifier(classifier, X_validation, y_validation):\n",
    "    y_validation=pd.to_numeric(y_validation)\n",
    "    predictions=classifier.predict(X_validation)\n",
    "    \n",
    "    actuals=y_validation\n",
    "    Z=list(zip(actuals,predictions))\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(predictions,actuals)\n",
    "    \n",
    "    # Print the precision and recall, among other metrics\n",
    "    print(metrics.classification_report(predictions,actuals))\n",
    "    \n",
    "    return(accuracy_score(predictions,actuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\SentimemtAnalysis\\SentimentAnalysis'\n",
    "os.chdir(path)\n",
    "onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "filename='train.csv'\n",
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "stopwords=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "df=pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  sentiment\n",
       "0                I`d have responded, if I were going          0\n",
       "1      Sooo SAD I will miss you here in San Diego!!!         -1\n",
       "2                          my boss is bullying me...         -1\n",
       "3                     what interview! leave me alone         -1\n",
       "4   Sons of ****, why couldn`t they put them on t...         -1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "df.columns=['ID','text','selected_text','sentiment']\n",
    "df=df[['text','sentiment']]\n",
    "df=df.replace({'positive': 1,'negative':-1,'neutral':0})\n",
    "df=df.loc[df['sentiment'].isin([1,-1,0])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index                                               text  sentiment\n",
       "0      0               [i, d, have, respond, if, i, be, go]          0\n",
       "1      1  [sooo, sad, i, will, miss, you, here, in, san,...         -1\n",
       "2      2                           [my, bos, be, bully, me]         -1\n",
       "3      3                [what, interview, leave, me, alone]         -1\n",
       "4      4  [son, of, why, couldn, t, they, put, them, on,...         -1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[i, d, have, respond, if, i, be, go]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[my, bos, be, bully, me]</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[what, interview, leave, me, alone]</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[son, of, why, couldn, t, they, put, them, on,...</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "df=df.reset_index() \n",
    "df=df.dropna(subset=['text', 'sentiment'])\n",
    "processed_tweets = process_all(df)\n",
    "processed_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tfidf, X) = create_features(processed_tweets, stopwords)\n",
    "\n",
    "y = create_labels(processed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "y_train=y_train.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "strting grid search\n",
      "Fitting 3 folds for each of 224 candidates, totalling 672 fits\n",
      "tuned hpyerparameters :(best parameters)  {'C': 1, 'class_weight': 'balanced', 'max_iter': 1000, 'multi_class': 'auto', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "accuracy : 0.6978436804084515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid=[{\n",
    "        'C':[0.01,0.1,1,10,100,1000,10000],\n",
    "        'penalty':[\"l1\",\"l2\"], 'solver':['liblinear'],\n",
    "        'multi_class':['ovr','auto'],\n",
    "        'max_iter':[1000] , 'class_weight': ['balanced',None]},\n",
    "    {\n",
    "        'C':[0.01,0.1,1,10,100,1000,10000],\n",
    "        'penalty':[\"l2\"], 'solver':['newton-cg','sag','saga','lbfgs'],\n",
    "        'multi_class':['ovr','auto','multinomial'],\n",
    "        'max_iter':[500], 'class_weight': ['balanced',None]\n",
    "    }]\n",
    "\n",
    "print(\"strting grid search\")  \n",
    "logreg_cv=GridSearchCV( LogisticRegression(), param_grid, verbose = 3, cv=3, n_jobs = 16)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'C': 1, 'class_weight': 'balanced', 'max_iter': 1000, 'multi_class': 'auto', 'penalty': 'l1', 'solver': 'liblinear'}\n              precision    recall  f1-score   support\n\n          -1       0.61      0.72      0.66      2196\n           0       0.74      0.66      0.69      4107\n           1       0.74      0.76      0.75      2766\n\n    accuracy                           0.70      9069\n   macro avg       0.70      0.71      0.70      9069\nweighted avg       0.71      0.70      0.70      9069\n\n"
     ]
    }
   ],
   "source": [
    "best_params = logreg_cv.best_params_\n",
    "print(best_params)\n",
    "logreg2=LogisticRegression(C=best_params['C'],penalty=best_params['penalty'],max_iter= best_params['max_iter'], multi_class=best_params['multi_class'], solver=best_params['solver'], class_weight=best_params['class_weight'])\n",
    "logreg2.fit(X_train,y_train)\n",
    "pred = logreg2.predict(X_test)\n",
    "print(metrics.classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   3909\n",
      "           1       0.72      0.75      0.74      2735\n",
      "\n",
      "    accuracy                           0.69      9069\n",
      "   macro avg       0.68      0.69      0.69      9069\n",
      "weighted avg       0.69      0.69      0.69      9069\n",
      "\n",
      "[0 1 0 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.65      0.64      2509\n",
      "           0       0.65      0.63      0.64      3773\n",
      "           1       0.72      0.73      0.73      2787\n",
      "\n",
      "    accuracy                           0.67      9069\n",
      "   macro avg       0.67      0.67      0.67      9069\n",
      "weighted avg       0.67      0.67      0.67      9069\n",
      "\n",
      "[0 1 1 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.59      0.59      2540\n",
      "           0       0.61      0.59      0.60      3774\n",
      "           1       0.67      0.69      0.68      2755\n",
      "\n",
      "    accuracy                           0.62      9069\n",
      "   macro avg       0.62      0.62      0.62      9069\n",
      "weighted avg       0.62      0.62      0.62      9069\n",
      "\n",
      "[0 1 1 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.56      0.56      2570\n",
      "           0       0.57      0.56      0.56      3717\n",
      "           1       0.63      0.64      0.63      2782\n",
      "\n",
      "    accuracy                           0.58      9069\n",
      "   macro avg       0.58      0.58      0.58      9069\n",
      "weighted avg       0.58      0.58      0.58      9069\n",
      "\n",
      "C:\\Users\\ajays\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ajays\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ajays\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[0 1 1 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.53      0.54      2628\n",
      "           0       0.54      0.54      0.54      3661\n",
      "           1       0.60      0.62      0.61      2780\n",
      "\n",
      "    accuracy                           0.56      9069\n",
      "   macro avg       0.56      0.56      0.56      9069\n",
      "weighted avg       0.56      0.56      0.56      9069\n",
      "\n",
      "[0 0 0 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.65      0.63      2347\n",
      "           0       0.70      0.61      0.65      4230\n",
      "           1       0.64      0.73      0.68      2492\n",
      "\n",
      "    accuracy                           0.65      9069\n",
      "   macro avg       0.65      0.67      0.65      9069\n",
      "weighted avg       0.66      0.65      0.65      9069\n",
      "\n",
      "[0 0 0 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.67      0.65      2363\n",
      "           0       0.71      0.63      0.67      4099\n",
      "           1       0.69      0.75      0.72      2607\n",
      "\n",
      "    accuracy                           0.68      9069\n",
      "   macro avg       0.67      0.69      0.68      9069\n",
      "weighted avg       0.68      0.68      0.68      9069\n",
      "\n",
      "[0 0 0 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.67      0.66      2484\n",
      "           0       0.69      0.65      0.67      3852\n",
      "           1       0.73      0.76      0.74      2733\n",
      "\n",
      "    accuracy                           0.69      9069\n",
      "   macro avg       0.69      0.69      0.69      9069\n",
      "weighted avg       0.69      0.69      0.69      9069\n",
      "\n",
      "[0 1 0 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.64      0.63      2514\n",
      "           0       0.65      0.62      0.64      3839\n",
      "           1       0.70      0.73      0.71      2716\n",
      "\n",
      "    accuracy                           0.66      9069\n",
      "   macro avg       0.66      0.66      0.66      9069\n",
      "weighted avg       0.66      0.66      0.66      9069\n",
      "\n",
      "[0 1 1 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.58      0.58      2529\n",
      "           0       0.60      0.58      0.59      3823\n",
      "           1       0.65      0.68      0.67      2717\n",
      "\n",
      "    accuracy                           0.61      9069\n",
      "   macro avg       0.61      0.61      0.61      9069\n",
      "weighted avg       0.61      0.61      0.61      9069\n",
      "\n",
      "C:\\Users\\ajays\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[0 1 1 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.55      0.55      2604\n",
      "           0       0.56      0.55      0.56      3716\n",
      "           1       0.62      0.64      0.63      2749\n",
      "\n",
      "    accuracy                           0.58      9069\n",
      "   macro avg       0.58      0.58      0.58      9069\n",
      "weighted avg       0.58      0.58      0.58      9069\n",
      "\n",
      "C:\\Users\\ajays\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[0 1 1 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.54      0.54      2626\n",
      "           0       0.54      0.55      0.55      3636\n",
      "           1       0.61      0.62      0.62      2807\n",
      "\n",
      "    accuracy                           0.57      9069\n",
      "   macro avg       0.57      0.57      0.57      9069\n",
      "weighted avg       0.57      0.57      0.57      9069\n",
      "\n",
      "[0 0 0 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.65      0.63      2347\n",
      "           0       0.70      0.61      0.65      4230\n",
      "           1       0.64      0.73      0.68      2492\n",
      "\n",
      "    accuracy                           0.65      9069\n",
      "   macro avg       0.65      0.67      0.65      9069\n",
      "weighted avg       0.66      0.65      0.65      9069\n",
      "\n",
      "[0 0 0 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.67      0.65      2363\n",
      "           0       0.71      0.63      0.67      4099\n",
      "           1       0.69      0.75      0.72      2607\n",
      "\n",
      "    accuracy                           0.68      9069\n",
      "   macro avg       0.67      0.69      0.68      9069\n",
      "weighted avg       0.68      0.68      0.68      9069\n",
      "\n",
      "[0 0 0 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.67      0.66      2484\n",
      "           0       0.69      0.65      0.67      3852\n",
      "           1       0.73      0.76      0.74      2733\n",
      "\n",
      "    accuracy                           0.69      9069\n",
      "   macro avg       0.69      0.69      0.69      9069\n",
      "weighted avg       0.69      0.69      0.69      9069\n",
      "\n",
      "[0 1 0 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.64      0.63      2514\n",
      "           0       0.65      0.62      0.64      3839\n",
      "           1       0.70      0.73      0.71      2716\n",
      "\n",
      "    accuracy                           0.66      9069\n",
      "   macro avg       0.66      0.66      0.66      9069\n",
      "weighted avg       0.66      0.66      0.66      9069\n",
      "\n",
      "[0 1 1 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.58      0.58      2529\n",
      "           0       0.60      0.58      0.59      3823\n",
      "           1       0.65      0.68      0.67      2717\n",
      "\n",
      "    accuracy                           0.61      9069\n",
      "   macro avg       0.61      0.61      0.61      9069\n",
      "weighted avg       0.61      0.61      0.61      9069\n",
      "\n",
      "C:\\Users\\ajays\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[0 1 1 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.55      0.55      2604\n",
      "           0       0.56      0.55      0.56      3716\n",
      "           1       0.62      0.64      0.63      2749\n",
      "\n",
      "    accuracy                           0.58      9069\n",
      "   macro avg       0.58      0.58      0.58      9069\n",
      "weighted avg       0.58      0.58      0.58      9069\n",
      "\n",
      "[0 1 1 ... 0 0 1] 2707     0\n",
      "24003    1\n",
      "8172     0\n",
      "3081     0\n",
      "1693     1\n",
      "        ..\n",
      "26578    0\n",
      "23652    0\n",
      "21585    0\n",
      "22847    0\n",
      "16394    1\n",
      "Name: sentiment, Length: 9069, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.54      0.54      2626\n",
      "           0       0.54      0.55      0.55      3636\n",
      "           1       0.61      0.62      0.62      2807\n",
      "\n",
      "    accuracy                           0.57      9069\n",
      "   macro avg       0.57      0.57      0.57      9069\n",
      "weighted avg       0.57      0.57      0.57      9069\n",
      "\n",
      "[('liblinear', 'ovr', 'l1', 0.01, 0.40423420443268276), ('liblinear', 'ovr', 'l1', 0.1, 0.6310508325063403), ('liblinear', 'ovr', 'l1', 1, 0.7042672841548131), ('liblinear', 'ovr', 'l1', 10, 0.6610431139045099), ('liblinear', 'ovr', 'l1', 100, 0.5980813761164406), ('liblinear', 'ovr', 'l1', 1000, 0.5700738780460911), ('liblinear', 'ovr', 'l1', 10000, 0.5627963391774176), ('liblinear', 'ovr', 'l2', 0.01, 0.5354504355496748), ('liblinear', 'ovr', 'l2', 0.1, 0.6565222185466976), ('liblinear', 'ovr', 'l2', 1, 0.6864042342044326), ('liblinear', 'ovr', 'l2', 10, 0.6673282611092733), ('liblinear', 'ovr', 'l2', 100, 0.6193626640202889), ('liblinear', 'ovr', 'l2', 1000, 0.5823133752343147), ('liblinear', 'ovr', 'l2', 10000, 0.565111919726541), ('liblinear', 'auto', 'l1', 0.01, 0.40423420443268276), ('liblinear', 'auto', 'l1', 0.1, 0.6310508325063403), ('liblinear', 'auto', 'l1', 1, 0.7042672841548131), ('liblinear', 'auto', 'l1', 10, 0.6614841768662476), ('liblinear', 'auto', 'l1', 100, 0.5991840335207851), ('liblinear', 'auto', 'l1', 1000, 0.57227919285478), ('liblinear', 'auto', 'l1', 10000, 0.5634579336200243), ('liblinear', 'auto', 'l2', 0.01, 0.5354504355496748), ('liblinear', 'auto', 'l2', 0.1, 0.6565222185466976), ('liblinear', 'auto', 'l2', 1, 0.6864042342044326), ('liblinear', 'auto', 'l2', 10, 0.6673282611092733), ('liblinear', 'auto', 'l2', 100, 0.6193626640202889), ('liblinear', 'auto', 'l2', 1000, 0.5823133752343147), ('liblinear', 'auto', 'l2', 10000, 0.565111919726541), ('newton-cg', 'ovr', 'l2', 0.01, 0.6431800639541294), ('newton-cg', 'ovr', 'l2', 0.1, 0.6682103870327489), ('newton-cg', 'ovr', 'l2', 1, 0.6853015768000882), ('newton-cg', 'ovr', 'l2', 10, 0.6672179953688389), ('newton-cg', 'ovr', 'l2', 100, 0.6194729297607233), ('newton-cg', 'ovr', 'l2', 1000, 0.5825339067151836), ('newton-cg', 'ovr', 'l2', 10000, 0.563898996581762), ('newton-cg', 'auto', 'l2', 0.01, 0.6545374352188775), ('newton-cg', 'auto', 'l2', 0.1, 0.6775829749696769), ('newton-cg', 'auto', 'l2', 1, 0.6888300804939905), ('newton-cg', 'auto', 'l2', 10, 0.6581762046532142), ('newton-cg', 'auto', 'l2', 100, 0.6092182159003198), ('newton-cg', 'auto', 'l2', 1000, 0.5780130113573713), ('newton-cg', 'auto', 'l2', 10000, 0.5650016539861065), ('newton-cg', 'multinomial', 'l2', 0.01, 0.6545374352188775), ('newton-cg', 'multinomial', 'l2', 0.1, 0.6775829749696769), ('newton-cg', 'multinomial', 'l2', 1, 0.6888300804939905), ('newton-cg', 'multinomial', 'l2', 10, 0.6581762046532142), ('newton-cg', 'multinomial', 'l2', 100, 0.6092182159003198), ('newton-cg', 'multinomial', 'l2', 1000, 0.5780130113573713), ('newton-cg', 'multinomial', 'l2', 10000, 0.5650016539861065), ('sag', 'ovr', 'l2', 0.01, 0.643069798213695), ('sag', 'ovr', 'l2', 0.1, 0.6682103870327489), ('sag', 'ovr', 'l2', 1, 0.6853015768000882), ('sag', 'ovr', 'l2', 10, 0.6672179953688389), ('sag', 'ovr', 'l2', 100, 0.6193626640202889), ('sag', 'ovr', 'l2', 1000, 0.5829749696769214), ('sag', 'ovr', 'l2', 10000, 0.5715073326717389), ('sag', 'auto', 'l2', 0.01, 0.6546477009593119), ('sag', 'auto', 'l2', 0.1, 0.6775829749696769), ('sag', 'auto', 'l2', 1, 0.6888300804939905), ('sag', 'auto', 'l2', 10, 0.6581762046532142), ('sag', 'auto', 'l2', 100, 0.6094387473811886), ('sag', 'auto', 'l2', 1000, 0.5788951372808468), ('sag', 'auto', 'l2', 10000, 0.5687506891608777), ('sag', 'multinomial', 'l2', 0.01, 0.6545374352188775), ('sag', 'multinomial', 'l2', 0.1, 0.6775829749696769), ('sag', 'multinomial', 'l2', 1, 0.6888300804939905), ('sag', 'multinomial', 'l2', 10, 0.6581762046532142), ('sag', 'multinomial', 'l2', 100, 0.6095490131216231), ('sag', 'multinomial', 'l2', 1000, 0.578674605799978), ('sag', 'multinomial', 'l2', 10000, 0.5678685632374021), ('saga', 'ovr', 'l2', 0.01, 0.6436211269158673), ('saga', 'ovr', 'l2', 0.1, 0.6684309185136178), ('saga', 'ovr', 'l2', 1, 0.6854118425405227), ('saga', 'ovr', 'l2', 10, 0.6667769324071011), ('saga', 'ovr', 'l2', 100, 0.6193626640202889), ('saga', 'ovr', 'l2', 1000, 0.5852905502260448), ('saga', 'ovr', 'l2', 10000, 0.5759179622891167), ('saga', 'auto', 'l2', 0.01, 0.6545374352188775), ('saga', 'auto', 'l2', 0.1, 0.6775829749696769), ('saga', 'auto', 'l2', 1, 0.6890506119748594), ('saga', 'auto', 'l2', 10, 0.6582864703936487), ('saga', 'auto', 'l2', 100, 0.6095490131216231), ('saga', 'auto', 'l2', 1000, 0.5808799206086669), ('saga', 'auto', 'l2', 10000, 0.5718381298930423), ('saga', 'multinomial', 'l2', 0.01, 0.6546477009593119), ('saga', 'multinomial', 'l2', 0.1, 0.6774727092292425), ('saga', 'multinomial', 'l2', 1, 0.688940346234425), ('saga', 'multinomial', 'l2', 10, 0.6582864703936487), ('saga', 'multinomial', 'l2', 100, 0.6094387473811886), ('saga', 'multinomial', 'l2', 1000, 0.5804388576469292), ('saga', 'multinomial', 'l2', 10000, 0.5716175984121733), ('lbfgs', 'ovr', 'l2', 0.01, 0.6431800639541294), ('lbfgs', 'ovr', 'l2', 0.1, 0.6683206527731834), ('lbfgs', 'ovr', 'l2', 1, 0.6853015768000882), ('lbfgs', 'ovr', 'l2', 10, 0.6671077296284045), ('lbfgs', 'ovr', 'l2', 100, 0.6194729297607233), ('lbfgs', 'ovr', 'l2', 1000, 0.5827544381960524), ('lbfgs', 'ovr', 'l2', 10000, 0.5632374021391554), ('lbfgs', 'auto', 'l2', 0.01, 0.6547579666997464), ('lbfgs', 'auto', 'l2', 0.1, 0.6778035064505458), ('lbfgs', 'auto', 'l2', 1, 0.6888300804939905), ('lbfgs', 'auto', 'l2', 10, 0.6580659389127798), ('lbfgs', 'auto', 'l2', 100, 0.6094387473811886), ('lbfgs', 'auto', 'l2', 1000, 0.5781232770978058), ('lbfgs', 'auto', 'l2', 10000, 0.5668761715734921), ('lbfgs', 'multinomial', 'l2', 0.01, 0.6547579666997464), ('lbfgs', 'multinomial', 'l2', 0.1, 0.6778035064505458), ('lbfgs', 'multinomial', 'l2', 1, 0.6888300804939905), ('lbfgs', 'multinomial', 'l2', 10, 0.6580659389127798), ('lbfgs', 'multinomial', 'l2', 100, 0.6094387473811886), ('lbfgs', 'multinomial', 'l2', 1000, 0.5781232770978058), ('lbfgs', 'multinomial', 'l2', 10000, 0.5668761715734921)]\n",
      "C:\\Users\\ajays\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "def best_model_selection_report():\n",
    "    mainlist=[]\n",
    "\n",
    "    for parameters in param_grid:\n",
    "        for optimizer in parameters['solver']:\n",
    "            for multiclass in parameters['multi_class']:\n",
    "                for penalty in parameters['penalty']:\n",
    "                    for c in parameters['C']:\n",
    "                        logreg_clfr = LogisticRegression(C=c ,penalty=penalty,max_iter= 1000, multi_class=multiclass, solver=optimizer,  class_weight='balanced')\n",
    "                        logreg_clfr.fit(X_train,y_train)\n",
    "                        accuracy = evaluate_classifier(logreg_clfr, X_test, y_test)\n",
    "                        mainlist.append((optimizer,multiclass,penalty,c,accuracy))\n",
    "    return mainlist\n",
    "\n",
    "report = best_model_selection_report()\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    optimizer multiclass penalty         c  accuracy_mean  accuracy_min  \\\n0       lbfgs       auto      l2      0.01       0.654758      0.654758   \n1       lbfgs       auto      l2      0.10       0.677804      0.677804   \n2       lbfgs       auto      l2      1.00       0.688830      0.688830   \n3       lbfgs       auto      l2     10.00       0.658066      0.658066   \n4       lbfgs       auto      l2    100.00       0.609439      0.609439   \n..        ...        ...     ...       ...            ...           ...   \n107      saga        ovr      l2      1.00       0.685412      0.685412   \n108      saga        ovr      l2     10.00       0.666777      0.666777   \n109      saga        ovr      l2    100.00       0.619363      0.619363   \n110      saga        ovr      l2   1000.00       0.585291      0.585291   \n111      saga        ovr      l2  10000.00       0.575918      0.575918   \n\n     accuracy_max  \n0        0.654758  \n1        0.677804  \n2        0.688830  \n3        0.658066  \n4        0.609439  \n..            ...  \n107      0.685412  \n108      0.666777  \n109      0.619363  \n110      0.585291  \n111      0.575918  \n\n[112 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "results=pd.DataFrame(report)\n",
    "results.columns=['optimizer','multiclass','penalty','c','accuracy']\n",
    "results= results.groupby(['optimizer','multiclass','penalty','c']).agg({'accuracy': ['mean', 'min', 'max']})\n",
    "results.columns = ['accuracy_mean', 'accuracy_min', 'accuracy_max']\n",
    "results=pd.DataFrame(results)\n",
    "results=results.reset_index()\n",
    "results.to_excel(r'D:\\SentimemtAnalysis\\SentimentAnalysis\\Ajay_codes\\LogReg_report.xlsx', index = False)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}